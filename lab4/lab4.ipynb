{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ChiefGokhlayeh/aibv/blob/master/lab4/lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Q5g_O1GeNH0"
   },
   "source": [
    "# Labor 4 Deep Learning für die Solarzelleninspektion mit CNN\n",
    "\n",
    "Im Kurs **(IE/DHL) Angewandte industrielle Bildverarbeitung S22** der **Hochschule für Angewandte Wissenschaften Hamburg**. Durchgeführt von:\n",
    "\n",
    "* **Andreas Baulig**\n",
    "* **Fabian Mahler**\n",
    "\n",
    "Laborbetreuung:\n",
    "\n",
    "* **Prof. Dr.-Ing. Dipl.-Kfm. J. Dahlkemper**\n",
    "\n",
    "## Ziel\n",
    "\n",
    "In diesem Versuch soll ein auf der Bilddatenbank ImageNet pre-trained CNN mit einem von Grund auf trainiertem CNN im Hinblick auf die Leistungsfähigkeit der Klassifizierung von Solarzellen auf Basis derer Elektrolumineszenz-Bilder verglichen werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktpE-SJOeNH5"
   },
   "source": [
    "## Vorbereitung\n",
    "\n",
    "Zunächst wird geprüft, ob die für das Labor notwendigen Python Pakete installiert sind. Darunter fällt auch ein Test, ob TensorFlow mit GPU-Beschleunigung arbeiten kann.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "from keras.applications import vgg16\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizer_v2.rmsprop import RMSProp\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-y9GYoo-eNH6"
   },
   "outputs": [],
   "source": [
    "# Check if GPU is present\n",
    "if tf.test.gpu_device_name():\n",
    "    print(f\"Default GPU Device: {tf.test.gpu_device_name()}\")\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLaHyQ9Lmtve"
   },
   "source": [
    "**NUR IN GOOGLE COLAB!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rKPY8M26mtVI"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab  # noqa: F401 E402\n",
    "\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in Google Colab.\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Not running in Google Colab.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbqNprelnLe9"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import drive  # noqa: E402\n",
    "\n",
    "    drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faDHrIcWnSb0"
   },
   "outputs": [],
   "source": [
    "def extract_dataset(fileobj, data_dir):\n",
    "    with zipfile.ZipFile(fileobj) as z:\n",
    "        for member in tqdm(\n",
    "            z.infolist(), desc=f\"Extracting to {os.path.normpath(data_dir)}\"\n",
    "        ):\n",
    "            z.extract(member, data_dir)\n",
    "\n",
    "\n",
    "if IN_COLAB:\n",
    "    # In Google Colab we have to first download the zip file from the\n",
    "    # repository.\n",
    "    data_dir = \"/content/data\"\n",
    "    dataset_source_url = \"https://media.githubusercontent.com/media/ChiefGokhlayeh/aibv/master/data/multilabel_small.zip\"\n",
    "    with requests.get(dataset_source_url) as req:\n",
    "        req.raise_for_status()\n",
    "\n",
    "        extract_dataset(io.BytesIO(req.content), data_dir)\n",
    "\n",
    "else:\n",
    "    # Assume we are executing within the repository, so the zip file should be\n",
    "    # available locally.\n",
    "    data_dir = \"../data\"\n",
    "    dataset_source_path = \"../data/multilabel_small.zip\"\n",
    "\n",
    "    with open(dataset_source_path, \"rb\") as f:\n",
    "        extract_dataset(f, data_dir)\n",
    "\n",
    "multilabel_dir = os.path.join(data_dir, \"multilabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ykrd_MvTmI5z"
   },
   "source": [
    "## Bildtransformationen mit [`ImageDataGenerator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)\n",
    "\n",
    "Keras Preprocessing bietet die Möglichkeit einen Bilderdatensatz mit synthetischen Transformationen der Originalbilder zu ergänzen. Die entsprechende Python Klasse dafür heißt [`ImageDataGenerator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) und befindet sich im Modul `keras.preprocessing.image`. Die Bildgenerierung arbeitet in zwei Schritten. Zunächst wird der `ImageDataGenerator` mit einer Reihe von Transformationsparametern instantiiert. So wird festgelegt welche Veränderungen der `ImageDataGenerator` durchführen soll, um aus einem Originalbild ein neues synthetisches Bild zu erzeugen. Die Transformationen werden zufällig angewandt. Auch ist die Reihenfolge der Eingangsbilder randomisiert.\n",
    "\n",
    "Aufgrund der speziellen Aufnahmebedingungen für Elektrolumineszenzbilder mit dem MBJ EL-Messplatz sind die Aufnahmen bereits in bestimmter Hinsicht normalisiert. Für die Solarzelleninspektion mit CNNs kommen folgende Transformationen zum Einsatz:\n",
    "\n",
    "* `brightness_range` zur Simulation unterschiedlicher Leuchtintensitäten der Solarzelle.\n",
    "* `height_shift_range` zur vertikalen Translation der Solarzellen um leichte Ausrichtungsfehler des EL-Messplatzes zu simulieren.\n",
    "* `horizontal_flip` zur Horizontalen Spiegelung der Bilder. Dies Hilft, um Lokalätätsbiasse der Defekte im gegeben Trainingsdatensatz zu kompensieren.\n",
    "* `shear_range` zur Scherung der Bilder, um leichte Montagefehler der Solarzelle im EL-Messplatz zu simulieren.\n",
    "* `vertical_flip` zur Vertikalen Spiegelung der Bilder. Dies Hilft, um Lokalätätsbiasse der Defekte im gegeben Trainingsdatensatz zu kompensieren.\n",
    "* `width_shift_range` zur horizontalen Translation der Solarzellen, um leichte Ausrichtungsfehler des EL-Messplatzes zu simulieren.\n",
    "\n",
    "Mit dem vor-parametrierten `ImageDataGenerator` können nun die Originalbilder geladen werden. Um das Labeling beizubehalten, existiert die Methode [`ImageDataGenerator::flow_from_dataframe()`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_dataframe). Sie erwartet mindestens zwei Parameter: ein [`pandas.DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) mit den Bilddateinamen und zugehörigen Labels, und den Pfad einem Wurzelverzeichnis in dem die Dateien abliegen. Die im Datensatz gelieferte Label-CSV ist für Multi-Labeling ausgelegt und hat die Struktur:\n",
    "\n",
    "|File|crack|darkarea|finger|\n",
    "|----|-----|--------|------|\n",
    "|0001.jpg|0|0|0|\n",
    "|0002.jpg|0|0|0|\n",
    "|0003.jpg|0|0|1|\n",
    "|0004.jpg|0|0|1|\n",
    "|...|...|...|...|\n",
    "|0022.jpg|0|1|1|\n",
    "|...|...|...|...|\n",
    "\n",
    "Zu erkennen ist, dass für jedes Bild bis zu drei Labels vergeben werden können. Die Menge der Fehlerklassen lautet $L = \\{ \\mathrm{crack}, \\mathrm{darkarea}, \\mathrm{finger} \\}$. Für jedes Bild gilt $y \\subseteq L$, wobei die leere Menge $y = \\emptyset$ eine Solarzelle ohne Defekte darstellt. \n",
    "\n",
    "### Siehe auch\n",
    "\n",
    "* [API Dokumentation `tf.keras.preprocessing.image.ImageDataGenerator`  |  TensorFlow Core v2.9.1](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)\n",
    "* [Image Augmentation for Deep Learning using Keras and Histogram Equalization | by Ryan Allred | Towards Data Science](https://towardsdatascience.com/image-augmentationfor-deep-learning-using-keras-and-histogram-equalization-9329f6ae5085)\n",
    "\n",
    "### Hinweis\n",
    "\n",
    "Die verwendete `ImageDataGenerator` ist mit TensorFlow v2.9.0 als veraltet (deprecated) markiert worden. Zukünftige Implementierungen sollten die neuen APIs von [Keras Preprocessing](https://keras.io/api/preprocessing/image/) nutzen. Aufgrund der relativen Neuheit dieser Version setzt dieses Labor noch setzt auf TensorFlow v2.8.1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-o7Lfl-8wlj"
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(os.path.join(multilabel_dir, \"labels.csv\"))\n",
    "\n",
    "print(f\"Dataset has a total of {len(labels_df)} items.\")\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(\n",
    "    brightness_range=(0.3, 1.1),\n",
    "    cval=0,\n",
    "    fill_mode=\"constant\",\n",
    "    height_shift_range=0.009,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=0,\n",
    "    validation_split=0.2,\n",
    "    shear_range=0.1,\n",
    "    vertical_flip=True,\n",
    "    width_shift_range=0.0085,\n",
    "    preprocessing_function=vgg16.preprocess_input,\n",
    ")\n",
    "\n",
    "imggen_sample_size = 8\n",
    "sample_batch_size = 16\n",
    "\n",
    "label_names = labels_df.columns[1:].to_list()\n",
    "\n",
    "flow_kwargs = {\n",
    "    \"batch_size\": sample_batch_size,\n",
    "    \"class_mode\": \"raw\",\n",
    "    \"color_mode\": \"rgb\",\n",
    "    \"dataframe\": labels_df,\n",
    "    \"directory\": multilabel_dir,\n",
    "    \"shuffle\": True,\n",
    "    \"target_size\": (128, 128),\n",
    "    \"x_col\": \"File\",\n",
    "    \"y_col\": label_names,\n",
    "}\n",
    "\n",
    "train_iter = image_gen.flow_from_dataframe(\n",
    "    subset=\"training\",\n",
    "    **flow_kwargs,\n",
    ")\n",
    "valid_iter = image_gen.flow_from_dataframe(\n",
    "    subset=\"validation\",\n",
    "    **flow_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 1\n",
    "fig, axs = plt.subplots(num_rows, imggen_sample_size, squeeze=False, figsize=(20, 5))\n",
    "\n",
    "for i in range(num_rows):\n",
    "    batch, labels = train_iter.next()\n",
    "    for j, (sample, label) in enumerate(\n",
    "        itertools.islice(zip(batch, labels), imggen_sample_size)\n",
    "    ):\n",
    "        ax = axs[i, j]\n",
    "        black = sample.min(axis=0)\n",
    "        white = sample.max(axis=0)\n",
    "        scale = (white - black) / 255\n",
    "        img = (sample - black).astype(np.uint8)\n",
    "        ax.imshow(img)\n",
    "        labels_s = pd.Series(label, index=label_names)\n",
    "        ax.set_title(\", \".join(labels_s.index[labels_s == 1].to_list()) or \"ok\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erzeuge CNN Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = vgg16.VGG16(\n",
    "    include_top=False,\n",
    "    classes=len(label_names),\n",
    "    input_shape=flow_kwargs[\"target_size\"] + (3,),\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(label_names), activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=RMSProp(learning_rate=10**-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=3),\n",
    "    ModelCheckpoint(filepath=\"lab4_model.h5\", monitor=\"val_loss\", save_best_only=True),\n",
    "]\n",
    "\n",
    "hist = model.fit(\n",
    "    train_iter,\n",
    "    callbacks=callbacks,\n",
    "    epochs=20,\n",
    "    validation_data=valid_iter,\n",
    ")\n",
    "print(\n",
    "    f\"Model fitting completed with final validation accuracy={hist.history['val_accuracy'][-1]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 6))\n",
    "\n",
    "ax = axs[0]\n",
    "ax.plot(hist.history[\"val_accuracy\"])\n",
    "ax.set_title(\"Validation Accuracy\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.grid(True)\n",
    "\n",
    "ax = axs[1]\n",
    "ax.plot(hist.history[\"val_loss\"])\n",
    "ax.set_title(\"Validation Loss\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.grid(True)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oodhf4eXfVMN"
   },
   "source": [
    "## **Meta**: Google Colab Code Formatierung und Aufräumen\n",
    "\n",
    "Erlaubt es die Codezellen dieses Notebooks zu formatieren und etwaige Zellinhalte zu löschen. Besonderes letzteres sollte vor jedem `git commit` durchgeführt werden, um die `.ipynb` Datei klein zuhalten.\n",
    "\n",
    "Nach dem Ausführen der Tools **nicht speichern**, stattdessen Seite mit `F5` neu laden. **Nur** für Verwendung in Google Colab gedacht. \n",
    "\n",
    "Inspiriert von https://stackoverflow.com/a/71001241.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3C9SlXvm5H4"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    %pip install black[jupyter] nbstripout\n",
    "    !black '/content/drive/MyDrive/Colab Notebooks/lab4.ipynb'\n",
    "    !nbstripout '/content/drive/MyDrive/Colab Notebooks/lab4.ipynb'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "lab4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
