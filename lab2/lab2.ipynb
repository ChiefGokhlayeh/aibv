{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elektrolumineszenz-Prüfung von Solarzellen - klassische Bildverarbeitung\n",
    "\n",
    "Programmgerüst als Hilfestellung zu Labor 2\n",
    "\n",
    "Bitte zunächst Laboraufgabe und dann die per `# TODO` gekennzeichneten Hinweise beachten\n",
    "\n",
    "## 1 Anzeigen der Bilder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "# Pfadangaben sind an den eigenen Speicherort der Datei splitted.zip anzupassen\n",
    "BASE_PATH = \"../data\"\n",
    "TRAIN_PATH = \"train\"\n",
    "VALIDATION_PATH = \"val\"\n",
    "\n",
    "SHOW = False  # ermöglicht eine Kurzansicht der Bilddateien, wenn auf True gesetzt\n",
    "EXPORT_REPORT = False  # exportiere Zwischenschritte und Endergebnisse in Datei\n",
    "\n",
    "if EXPORT_REPORT:\n",
    "    # Matplotlib plot Einstellungen für Laborbericht setzen\n",
    "    rc_fonts = {\n",
    "        \"font.family\": \"serif\",\n",
    "        \"text.usetex\": True,\n",
    "        \"text.latex.preamble\": r\"\\usepackage{libertine}\",\n",
    "    }\n",
    "    mpl.rcParams.update(rc_fonts)\n",
    "\n",
    "# Einlesen aller Verzeichnisse\n",
    "train_path = os.path.join(BASE_PATH, TRAIN_PATH)\n",
    "defect_classes = os.listdir(train_path)\n",
    "print(\"[i] Fehlerklassen in %s: %s\" % (train_path, defect_classes))\n",
    "\n",
    "# Anzeige aller Bilder der einzelnen Verzeichnisse, falls SHOW auf True gesetzt\n",
    "for class_idx, defect_class in enumerate(defect_classes):\n",
    "    files = os.listdir(os.path.join(train_path, defect_class))\n",
    "    print(\"[i] Klasse\", defect_class, \"mit %d Bildern\" % (len(files)))\n",
    "\n",
    "    if SHOW:\n",
    "        for file_idx, file in enumerate(files):\n",
    "            img = cv2.imread(os.path.join(train_path, defect_class, file))\n",
    "            cv2.imshow(\"Original\", img)\n",
    "            cv2.waitKey(100)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Anzeigen des jeweils ersten Bildes einer Fehlerklasse als Grundlage für die Entwicklung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzeige des ersten Bildes je Verzeichnis\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for class_idx, defect_class in enumerate(defect_classes):\n",
    "    files = os.listdir(os.path.join(train_path, defect_class))\n",
    "\n",
    "    img_bgr = cv2.imread(os.path.join(train_path, defect_class, files[0]))\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.subplot(1, len(defect_classes), class_idx + 1)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(defect_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Entwicklung der Segmentierung `my_segmentation` und Merkmalsextraktion `my_feature_extraction`\n",
    "\n",
    "**Hinweis**: Beschränken Sie sich zunächst auf einfache Filter wie Glättung und Median-Filter sowie die Auswahl von Bereichen auf der Basis der Helligkeit auch unter Nutzung der Funktion `cv2.adaptiveThreshold` und kombinieren Sie ggfs. mehrere Segmentierungsansätze zu einem Binärbild.\n",
    "\n",
    "Um eine flexible Merkmalsextraktion zu ermöglichen, übergeben Sie die Merkmale als Dictionary, z.B.:\n",
    "\n",
    "```\n",
    "features = {\n",
    "    'area': 1000,\n",
    "    'perimeter' : 345,\n",
    "    'circularity' : 0.5,\n",
    "    ...\n",
    "}\n",
    "\n",
    "\n",
    "print(features[\"area\"])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Allgemeine Segmentierungsfunktionen\n",
    "\n",
    "Sammlung von Funktionen zum vor-verarbeiten eines Grauwertbildes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_shading_correction(img: np.ndarray, brightness: float) -> np.ndarray:\n",
    "    X, Y = np.meshgrid(\n",
    "        np.linspace(-1, 1, img.shape[0]), np.linspace(-1, 1, img.shape[1])\n",
    "    )\n",
    "    img_shading = (\n",
    "        img\n",
    "        + np.exp(\n",
    "            -(\n",
    "                (1.5 * (X / np.abs(X).max() - 1)) ** 2 / 2\n",
    "                + (2 * (Y / np.abs(X).max() + 1)) ** 2 / 2\n",
    "            )\n",
    "        )\n",
    "        * img.max()\n",
    "        * brightness\n",
    "    )\n",
    "    return ((img_shading / img_shading.max()) * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def create_bus_mask(img_canny: np.ndarray, fig: plt.Figure = None) -> np.ndarray:\n",
    "    edge_finder = np.hstack(\n",
    "        (\n",
    "            np.full((img_canny.shape[0], 15), img_canny.min()),\n",
    "            np.full((img_canny.shape[0], 15), img_canny.max()),\n",
    "            np.full((img_canny.shape[0], 15), img_canny.min()),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    x_corr = cv2.matchTemplate(img_canny, edge_finder, cv2.TM_CCORR)[0, :]\n",
    "    x_peaks = np.array(\n",
    "        [\n",
    "            np.argmax(x_corr[: x_corr.size // 2]),\n",
    "            np.argmax(x_corr[x_corr.size // 2 :]) + x_corr.size // 2,\n",
    "        ]\n",
    "    )\n",
    "    x_edges = x_peaks + edge_finder.shape[1] // 2\n",
    "\n",
    "    y_corr = cv2.matchTemplate(img_canny, edge_finder.T, cv2.TM_CCORR)[:, 0]\n",
    "    y_peaks = np.array(\n",
    "        [\n",
    "            np.argmax(y_corr[: y_corr.size // 16]),\n",
    "            np.argmax(y_corr[15 * y_corr.size // 16 :]) + 15 * y_corr.size // 16,\n",
    "        ]\n",
    "    )\n",
    "    y_edges = y_peaks + edge_finder.shape[1] // 2\n",
    "    y_bar_peaks = np.array(\n",
    "        [\n",
    "            np.argmax(y_corr[y_corr.size // 16 : y_peaks[0] + 140]) + y_corr.size // 16,\n",
    "            np.argmax(y_corr[y_peaks[0] + 140 : y_corr.size // 4]) + y_peaks[0] + 140,\n",
    "            np.argmax(y_corr[y_corr.size // 4 : y_corr.size // 2]) + y_corr.size // 4,\n",
    "            np.argmax(y_corr[y_corr.size // 2 : 3 * y_corr.size // 4])\n",
    "            + y_corr.size // 2,\n",
    "            np.argmax(y_corr[3 * y_corr.size // 4 : y_peaks[1] - 140])\n",
    "            + 3 * y_corr.size // 4,\n",
    "            np.argmax(y_corr[y_peaks[1] - 140 : 15 * y_corr.size // 16])\n",
    "            + y_peaks[1]\n",
    "            - 140,\n",
    "        ]\n",
    "    )\n",
    "    y_bars = (\n",
    "        y_bar_peaks.reshape(-1, 2).mean(axis=1).astype(\"int\")\n",
    "        + edge_finder.shape[1] // 2\n",
    "    )\n",
    "\n",
    "    img_mask = np.ones_like(img_canny, dtype=img_canny.dtype)\n",
    "    img_mask[:, : x_edges[0]] = np.zeros((img_mask.shape[0], x_edges[0]))\n",
    "    img_mask[:, x_edges[1] :] = np.zeros(\n",
    "        (img_mask.shape[0], img_mask.shape[1] - x_edges[1])\n",
    "    )\n",
    "    bar_half_width = 25\n",
    "    for bar in y_bars:\n",
    "        y_corr[bar - bar_half_width : bar + bar_half_width] = np.zeros(\n",
    "            (bar_half_width * 2,)\n",
    "        )\n",
    "        img_mask[bar - bar_half_width : bar + bar_half_width, :] = np.zeros(\n",
    "            (bar_half_width * 2, img_mask.shape[1])\n",
    "        )\n",
    "\n",
    "    img_mask[: y_edges[0], :] = np.zeros((y_edges[0], img_mask.shape[1]))\n",
    "    img_mask[y_edges[1] :, :] = np.zeros(\n",
    "        (img_mask.shape[0] - y_edges[1], img_mask.shape[1])\n",
    "    )\n",
    "    corner_size = 70\n",
    "    for y_idx, y in enumerate(np.arange(y_edges[0], y_edges[0] + corner_size)):\n",
    "        for x in np.arange(x_edges[0], x_edges[0] + corner_size):\n",
    "            img_mask[y, max(x - y_idx, x_edges[0])] = 0\n",
    "    for y_idx, y in enumerate(np.arange(y_edges[0], y_edges[0] + corner_size)):\n",
    "        for x in np.arange(x_edges[1] - corner_size, x_edges[1]):\n",
    "            img_mask[y, min(x + y_idx, x_edges[1])] = 0\n",
    "    for y_idx, y in enumerate(np.arange(y_edges[1] - corner_size, y_edges[1])):\n",
    "        for x in np.arange(x_edges[0], x_edges[0] + corner_size):\n",
    "            img_mask[y, max(x - (corner_size - y_idx), x_edges[0])] = 0\n",
    "    for y_idx, y in enumerate(np.arange(y_edges[1] - corner_size, y_edges[1])):\n",
    "        for x in np.arange(x_edges[1] - corner_size, x_edges[1]):\n",
    "            img_mask[y, min(x + (corner_size - y_idx), x_edges[1])] = 0\n",
    "\n",
    "    if fig is not None:\n",
    "        ax_img = fig.add_axes([0.3, 0.3, 0.6, 0.6])\n",
    "        ax_finder_y = fig.add_axes([0.3, 0.9, 0.6, 0.05])\n",
    "        ax_corr_y = fig.add_axes([0.05, 0.3, 0.225, 0.6])\n",
    "        ax_finder_x = fig.add_axes([0.9, 0.3, 0.05, 0.6])\n",
    "        ax_corr_x = fig.add_axes([0.3, 0.05, 0.6, 0.225])\n",
    "\n",
    "        ax_finder_x.imshow(edge_finder, cmap=\"Greys\")\n",
    "        ax_finder_x.set_xticks([])\n",
    "        ax_finder_x.set_yticks([])\n",
    "        ax_finder_x.get_yaxis().set_label_position(\"right\")\n",
    "        ax_finder_x.set_ylabel(\"X Edge-Finder (invertiert)\")\n",
    "        ax_finder_y.imshow(edge_finder.T, cmap=\"Greys\")\n",
    "        ax_finder_y.set_xticks([])\n",
    "        ax_finder_y.set_yticks([])\n",
    "        ax_finder_y.get_xaxis().set_label_position(\"top\")\n",
    "        ax_finder_y.set_xlabel(\"Y Edge-Finder (invertiert)\")\n",
    "\n",
    "        y_corr_norm = np.pad(\n",
    "            y_corr / y_corr.max(),\n",
    "            (\n",
    "                int(np.floor(edge_finder.shape[1] / 2)),\n",
    "                int(np.ceil(np.floor(edge_finder.shape[1] / 2))),\n",
    "            ),\n",
    "        )\n",
    "        ax_corr_y.plot(y_corr_norm, np.arange(len(y_corr_norm)))\n",
    "        ax_corr_y.set_xlabel(\"Y Korrelation [norm]\")\n",
    "        ax_corr_y.set_xlim([0, 1])\n",
    "        ax_corr_y.set_ylim([0, len(y_corr_norm)])\n",
    "        ax_corr_y.grid(True)\n",
    "        ax_corr_y.get_xaxis().tick_top()\n",
    "        ax_corr_y.get_xaxis().set_label_position(\"top\")\n",
    "        ax_corr_y.set_xticks(np.linspace(0, 1, 5, endpoint=True))\n",
    "\n",
    "        ax_img.imshow(img_canny, cmap=\"Greys\")\n",
    "        ax_img.set_xticks([])\n",
    "        ax_img.set_yticks([])\n",
    "\n",
    "        x_corr_norm = np.pad(\n",
    "            x_corr / x_corr.max(),\n",
    "            (\n",
    "                int(np.floor(edge_finder.shape[1] / 2)),\n",
    "                int(np.ceil(np.floor(edge_finder.shape[1] / 2))),\n",
    "            ),\n",
    "        )\n",
    "        ax_corr_x.plot(np.arange(len(x_corr_norm)), x_corr_norm)\n",
    "        ax_corr_x.set_ylabel(\"X Korrelation [norm]\")\n",
    "        ax_corr_x.set_xlim([0, len(y_corr_norm)])\n",
    "        ax_corr_x.set_ylim([0, 1])\n",
    "        ax_corr_x.grid(True)\n",
    "        ax_corr_x.set_yticks(np.linspace(0, 1, 5, endpoint=True))\n",
    "\n",
    "    return img_mask\n",
    "\n",
    "\n",
    "def find_canny_edges(img: np.ndarray) -> np.ndarray:\n",
    "    img_med_blurred = cv2.medianBlur(img, ksize=11)\n",
    "    return cv2.Canny(img_med_blurred, np.percentile(img, 7), np.percentile(img, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentierung: a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_defects_a(img: np.ndarray, img_mask: np.ndarray) -> np.ndarray:\n",
    "    _, img_on = cv2.threshold(img, np.percentile(img, 60), 1, cv2.THRESH_BINARY)\n",
    "    _, img_off = cv2.threshold(img, np.percentile(img, 10), 1, cv2.THRESH_BINARY)\n",
    "\n",
    "    img_panel = cv2.adaptiveThreshold(\n",
    "        img,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        101,\n",
    "        5,\n",
    "    )\n",
    "    img_panel = (img_panel & ~img_on & img_mask) | (img_mask & ~img_off)\n",
    "    s = np.array([1, 0, 1], ndmin=2, dtype=img_panel.dtype)\n",
    "    img_defects = cv2.erode(img_panel, s, iterations=1)\n",
    "    return img_defects\n",
    "\n",
    "\n",
    "def apply_segmentation_a(img: np.ndarray, dbg_fig: plt.Figure = None) -> np.ndarray:\n",
    "    \"\"\"Hier entwickeln Sie die Bildvorverarbeitung und Segmentierung\n",
    "\n",
    "    Parameter img: einkanaliges Grauwertbild vom Typ np.uint8\n",
    "    Rückgabe img_final: einkanaliges Binärbild mit Wert 0 oder 255 vom Typ np.uint8\n",
    "\n",
    "    Beschreibung:\n",
    "    Diese Funktion beinhaltet Vorverarbeitung und Segmentierung und soll\n",
    "    möglichst alle Fehler idealerweise vollständig als Binärbild segmentieren\n",
    "    und dabei kleine Artefakte eliminieren.\n",
    "\n",
    "    \"\"\"\n",
    "    img_overexposed = ((img / np.percentile(img, 70)).clip(0, 1) * 255).astype(np.uint8)\n",
    "\n",
    "    img_shading = apply_shading_correction(img_overexposed, 0.08)\n",
    "\n",
    "    img_canny = find_canny_edges(img_shading)\n",
    "\n",
    "    img_mask = create_bus_mask(img_canny, fig=dbg_fig)\n",
    "\n",
    "    img_final = find_defects_a(img_shading, img_mask)\n",
    "\n",
    "    return ((img_final / img_final.max()) * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merkmalsextraktion: a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exctact_features_a(img_bin: np.ndarray):\n",
    "    \"\"\"Hier führen Sie die Merkmalsextration aus und visualisieren das Ergebnis\n",
    "\n",
    "    Parameter img_bin: segmentiertes Binärbild mit den Werten 0 oder 255 vom Datentyp np.uint8\n",
    "    Rückgabe cnt: Kontur des flächenmässig groessten Segments\n",
    "    Rückgabe features: Dictionary, das die Merkmale des durch cnt beschriebenen Segments zurückgibt\n",
    "\n",
    "    Diese Funktion ermittelt die von Ihnen ausgewählten Merkmale und speichert diese in einem Dictionary.\n",
    "    Es bietet sich an, hier mehr als 4 Merkmale zu berechnen, so dass spaeter die bestgeeignete Kombination\n",
    "    ausgewählt werden kann.\n",
    "\n",
    "    Hierbei ist zu beachten, dass auch eine leere Kontur behandelt werden muss und ein Dictionary zurückliefert.\n",
    "    In diesem Fall kann eine leere Kontur zurückgegeben werden, z.B. per cnt = None.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    cnts, _ = cv2.findContours(img_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    top_cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:1]\n",
    "    moments = [cv2.moments(cnt) for cnt in top_cnts]\n",
    "    directions = [\n",
    "        0.5 * np.arctan2(2 * m[\"mu11\"], m[\"mu20\"] - m[\"mu02\"]) for m in moments\n",
    "    ]\n",
    "    perimeters = [cv2.arcLength(cnt, True) for cnt in top_cnts]\n",
    "    eccentricity = [\n",
    "        ((m[\"mu20\"] - m[\"mu02\"]) ** 2 + 4 * m[\"mu11\"] ** 2)\n",
    "        / (m[\"mu20\"] + m[\"mu02\"]) ** 2\n",
    "        for m in moments\n",
    "    ]\n",
    "\n",
    "    cnt = max(cnts, key=cv2.contourArea)\n",
    "    features = {\n",
    "        \"area\": [i for i in map(cv2.contourArea, top_cnts)],\n",
    "        \"direction\": directions,\n",
    "        \"perimeter\": perimeters,\n",
    "        \"eccentricity\": eccentricity,\n",
    "    }\n",
    "\n",
    "    return cnt, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentierung: b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_defects_b(img: np.ndarray, img_mask: np.ndarray) -> np.ndarray:\n",
    "    # panel extraction\n",
    "    img_panel_adapt_thresh = cv2.adaptiveThreshold(\n",
    "        cv2.medianBlur(img, ksize=1),\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        201,\n",
    "        3,\n",
    "    )\n",
    "    img_panel_gauss_blurred = cv2.GaussianBlur(\n",
    "        img_panel_adapt_thresh, ksize=(3, 1), sigmaX=0\n",
    "    )\n",
    "    img_panel_blurred = cv2.medianBlur(img_panel_gauss_blurred, ksize=3)\n",
    "    _, img_panel_thresh = cv2.threshold(\n",
    "        img_panel_blurred, 30, 255, cv2.THRESH_BINARY_INV\n",
    "    )\n",
    "\n",
    "    # masking\n",
    "    img_panel_thresh &= img_mask\n",
    "\n",
    "    # cell border suppression\n",
    "    s_panel_dilate = cv2.getStructuringElement(cv2.MORPH_CROSS, (7, 11))\n",
    "    img_panel_dilate = cv2.dilate(img_panel_thresh, s_panel_dilate, iterations=2)\n",
    "    s_panel_erode = cv2.getStructuringElement(cv2.MORPH_CROSS, (11, 7))\n",
    "    img_panel_erode = cv2.erode(img_panel_dilate, s_panel_erode, iterations=1)\n",
    "\n",
    "    return img_panel_erode\n",
    "\n",
    "\n",
    "def apply_segmentation_b(img: np.ndarray, dbg_fig: plt.Figure = None) -> np.ndarray:\n",
    "    \"\"\"Hier entwickeln Sie die Bildvorverarbeitung und Segmentierung\n",
    "\n",
    "    Parameter img: einkanaliges Grauwertbild vom Typ np.uint8\n",
    "    Rückgabe img_final: einkanaliges Binärbild mit Wert 0 oder 255 vom Typ np.uint8\n",
    "\n",
    "    Beschreibung:\n",
    "    Diese Funktion beinhaltet Vorverarbeitung und Segmentierung und soll\n",
    "    möglichst alle Fehler idealerweise vollständig als Binärbild segmentieren\n",
    "    und dabei kleine Artefakte eliminieren.\n",
    "\n",
    "    \"\"\"\n",
    "    img_overexposed = ((img / np.percentile(img, 70)).clip(0, 1) * 255).astype(np.uint8)\n",
    "\n",
    "    img_shading = apply_shading_correction(img_overexposed, 0.1)\n",
    "\n",
    "    img_canny = find_canny_edges(img_shading)\n",
    "\n",
    "    img_mask = create_bus_mask(img_canny, fig=dbg_fig)\n",
    "\n",
    "    img_final = find_defects_b(img_shading, img_mask)\n",
    "\n",
    "    return ((img_final / img_final.max()) * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merkmalsextraktion: b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exctact_features_b(img_bin: np.ndarray):\n",
    "    \"\"\"Hier führen Sie die Merkmalsextration aus und visualisieren das Ergebnis\n",
    "\n",
    "    Parameter img_bin: segmentiertes Binärbild mit den Werten 0 oder 255 vom Datentyp np.uint8\n",
    "    Rückgabe cnt: Kontur des flächenmässig groessten Segments\n",
    "    Rückgabe features: Dictionary, das die Merkmale des durch cnt beschriebenen Segments zurückgibt\n",
    "\n",
    "    Diese Funktion ermittelt die von Ihnen ausgewählten Merkmale und speichert diese in einem Dictionary.\n",
    "    Es bietet sich an, hier mehr als 4 Merkmale zu berechnen, so dass spaeter die bestgeeignete Kombination\n",
    "    ausgewählt werden kann.\n",
    "\n",
    "    Hierbei ist zu beachten, dass auch eine leere Kontur behandelt werden muss und ein Dictionary zurückliefert.\n",
    "    In diesem Fall kann eine leere Kontur zurückgegeben werden, z.B. per cnt = None.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    cnts, _ = cv2.findContours(img_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    top_cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:1]\n",
    "    moments = [cv2.moments(cnt) for cnt in top_cnts]\n",
    "    areas = [i for i in map(cv2.contourArea, top_cnts)]\n",
    "    solidities = [\n",
    "        area / cv2.contourArea(cv2.convexHull(cnt))\n",
    "        for area, cnt in zip(areas, top_cnts)\n",
    "    ]\n",
    "    directions = [\n",
    "        0.5 * np.arctan2(2 * m[\"mu11\"], m[\"mu20\"] - m[\"mu02\"]) for m in moments\n",
    "    ]\n",
    "    eccentricity = [\n",
    "        ((m[\"mu20\"] - m[\"mu02\"]) ** 2 + 4 * m[\"mu11\"] ** 2)\n",
    "        / (m[\"mu20\"] + m[\"mu02\"]) ** 2\n",
    "        for m in moments\n",
    "    ]\n",
    "\n",
    "    cnt = max(cnts, key=cv2.contourArea)\n",
    "    features = {\n",
    "        \"area\": areas,\n",
    "        \"solidity\": solidities,\n",
    "        \"direction\": directions,\n",
    "        \"eccentricity\": eccentricity,\n",
    "    }\n",
    "\n",
    "    return cnt, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varianten\n",
    "\n",
    "Hier werden die Segmentierungs- und Merkmalsextraktionsvarianten kombiniert.\n",
    "\n",
    "* Variante 1:\n",
    "  * Segmentierung: a)\n",
    "  * Merkmalsextraktion: a)\n",
    "* Variante 2:\n",
    "  * Segmentierung: a)\n",
    "  * Merkmalsextraktion: b)\n",
    "* Variante 3:\n",
    "  * Segmentierung: b)\n",
    "  * Merkmalsextraktion: a)\n",
    "* Variante 4:\n",
    "  * Segmentierung: b)\n",
    "  * Merkmalsextraktion: b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = [\n",
    "    {\n",
    "        \"apply_segmentation\": apply_segmentation_a,\n",
    "        \"exctact_features\": exctact_features_a,\n",
    "    },\n",
    "    {\n",
    "        \"apply_segmentation\": apply_segmentation_a,\n",
    "        \"exctact_features\": exctact_features_b,\n",
    "    },\n",
    "    {\n",
    "        \"apply_segmentation\": apply_segmentation_b,\n",
    "        \"exctact_features\": exctact_features_a,\n",
    "    },\n",
    "    {\n",
    "        \"apply_segmentation\": apply_segmentation_b,\n",
    "        \"exctact_features\": exctact_features_b,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametrierung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant = 0  # wähle Variante der Segmentierung/Merkmalsextraktion\n",
    "k = 3  # wähle Anzahl Nachbarin in k-nearest neighbor\n",
    "\n",
    "# variant muss ein index innerhalb des variants arrays sein\n",
    "assert variant >= 0 and variant < len(variants)\n",
    "\n",
    "# k muss ungerade sein, um eine Mehrheitsentscheidung zu erlauben\n",
    "assert k % 2 == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anwenden der Segmentierung und Merkmalsextraktion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzeige des ersten Bildes je Verzeichnis als Original, Segmentiertes Binärbild und als Bounding Box im Originalbild\n",
    "fig = plt.figure(figsize=(30, 20), layout=\"tight\")\n",
    "\n",
    "class_count = len(defect_classes)\n",
    "\n",
    "for class_idx, defect_class in enumerate(defect_classes):\n",
    "    files = os.listdir(os.path.join(train_path, defect_class))\n",
    "\n",
    "    img_bgr = cv2.imread(os.path.join(train_path, defect_class, files[0]))\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ax = fig.add_subplot(3, class_count, class_idx + 1)\n",
    "    ax.imshow(img_rgb)\n",
    "    ax.set_title(defect_class)\n",
    "\n",
    "    img_gray_filtered = variants[variant][\"apply_segmentation\"](img_gray)\n",
    "    img_rgb_filtered = cv2.cvtColor(img_gray_filtered, cv2.COLOR_GRAY2RGB)\n",
    "    ax = fig.add_subplot(3, class_count, class_idx + 1 + class_count)\n",
    "    ax.imshow(img_rgb_filtered)\n",
    "    ax.set_title(\"filtered \" + defect_class)\n",
    "\n",
    "    cnt, features = variants[variant][\"exctact_features\"](img_gray_filtered)\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    img_rgb_cnt = cv2.rectangle(img_rgb, (x, y), (x + w, y + h), (255, 0, 0), 5)\n",
    "    ax = fig.add_subplot(3, class_count, class_idx + 1 + 2 * class_count)\n",
    "    ax.imshow(img_rgb_cnt)\n",
    "    ax.set_title(\"segmented \" + defect_class)\n",
    "\n",
    "    print(defect_class)\n",
    "    pprint.pprint(features)\n",
    "\n",
    "if EXPORT_REPORT:\n",
    "    dbg_fig = plt.figure(figsize=(5.7, 5.7), layout=\"tight\")\n",
    "    img_gray_filtered = variants[variant][\"apply_segmentation\"](\n",
    "        img_gray, dbg_fig=dbg_fig\n",
    "    )\n",
    "    dbg_fig.savefig(f\"report/images/bus_mask_{defect_classes[-1]}.eps\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Merkmalsraum für alle Trainingsdaten visualisieren\n",
    "\n",
    "Dieses Skript visualisiert den Merkmalsraum fuer genau 4 Merkmale und stellt jeweils die Kombination des ersten Merkmals mit jedem der anderen Merkmalen in einem zweidimensionalen Merkmalsraum dar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Festlegung der auszuwaehlenden Features - Die Anzeige ist auf genau 4 Merkmale programmiert\n",
    "FEATURES = [\n",
    "    [\n",
    "        \"area\",\n",
    "        \"direction\",\n",
    "        \"perimeter\",\n",
    "        \"eccentricity\",\n",
    "    ],\n",
    "    [\n",
    "        \"area\",\n",
    "        \"solidity\",\n",
    "        \"direction\",\n",
    "        \"eccentricity\",\n",
    "    ],\n",
    "    [\n",
    "        \"area\",\n",
    "        \"direction\",\n",
    "        \"perimeter\",\n",
    "        \"eccentricity\",\n",
    "    ],\n",
    "    [\n",
    "        \"area\",\n",
    "        \"solidity\",\n",
    "        \"direction\",\n",
    "        \"eccentricity\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "# Iteriere ueber alle Bilder, deren Klassenzugehoerigkeit durch defect_class bestimmt wird\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for class_idx, defect_class in enumerate(defect_classes):\n",
    "    files = os.listdir(os.path.join(train_path, defect_class))\n",
    "    print(\"[i] Klasse\", defect_class, \"mit %d Bildern\" % (len(files)))\n",
    "\n",
    "    for file_idx, file in enumerate(files):\n",
    "        img_bgr = cv2.imread(os.path.join(train_path, defect_class, file))\n",
    "        img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        img_gray_filtered = variants[variant][\"apply_segmentation\"](img_gray)\n",
    "        cnt, features = variants[variant][\"exctact_features\"](img_gray_filtered)\n",
    "        if features:\n",
    "            x_train.append(\n",
    "                [\n",
    "                    features[FEATURES[variant][0]],\n",
    "                    features[FEATURES[variant][1]],\n",
    "                    features[FEATURES[variant][2]],\n",
    "                    features[FEATURES[variant][3]],\n",
    "                ]\n",
    "            )\n",
    "            y_train.append(class_idx)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Anzeige des Merkmalsraums\n",
    "markers = [\"or\", \"og\", \"ob\", \"ok\"]\n",
    "fig = plt.figure(\"Merkmalsraum\", figsize=(10, 3), layout=\"tight\")\n",
    "\n",
    "for f, feature in enumerate(FEATURES[variant]):\n",
    "    if f == 0:\n",
    "        continue  # erste Grafik (FEATURES[variant][0] über sich selbst) wird übersprungen\n",
    "    ax = fig.add_subplot(1, 3, f)\n",
    "    for i, label in enumerate(defect_classes):\n",
    "        ax.plot(\n",
    "            x_train[y_train == i, 0],\n",
    "            x_train[y_train == i, f],\n",
    "            markers[i],\n",
    "            label=f\"\\\\texttt{{{label}}}\",\n",
    "            ms=2.5,\n",
    "        )\n",
    "    if f == len(FEATURES[variant]) // 2:\n",
    "        ax.legend()\n",
    "    ax.set_xlabel(FEATURES[variant][0])\n",
    "    ax.set_ylabel(feature)\n",
    "    ax.set_title(FEATURES[variant][0] + \" vs. \" + feature)\n",
    "\n",
    "if EXPORT_REPORT:\n",
    "    fig.savefig(f\"report/images/feature_space_var{variant}.eps\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Training\n",
    "\n",
    "**Wichtig**: Normierung ist nicht zu vergessen und bei der Klassifizierung müssen die hier erzeugten Normierungsparameter ohne Neuberechnung wiederverwendet werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(x_train, axis=0)  # Spaltenweise Mittelwerte berechnen\n",
    "stds = np.std(x_train, axis=0)  # Spaltenweise Standardabweichung berechnen\n",
    "\n",
    "train = (x_train - means) / stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Klassifizierung\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteriere über alle Bilder, deren Klassenzugehörigkeit durch defect_class bestimmt wird\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "# Einlesen aller Verzeichnisse\n",
    "validation_path = os.path.join(BASE_PATH, VALIDATION_PATH)\n",
    "print(defect_classes == os.listdir(validation_path))\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for class_idx, defect_class in enumerate(defect_classes):\n",
    "    files = os.listdir(os.path.join(validation_path, defect_class))\n",
    "    print(\"[i] Klasse\", defect_class, \"mit %d Bildern\" % (len(files)))\n",
    "\n",
    "    for file_idx, file in enumerate(files):\n",
    "        filenames.append(os.path.join(validation_path, defect_class, file))\n",
    "        img_bgr = cv2.imread(os.path.join(validation_path, defect_class, file))\n",
    "        img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        img_gray_filtered = variants[variant][\"apply_segmentation\"](img_gray)\n",
    "        cnt, features = variants[variant][\"exctact_features\"](img_gray_filtered)\n",
    "\n",
    "        x_val.append(\n",
    "            [\n",
    "                features[FEATURES[variant][0]],\n",
    "                features[FEATURES[variant][1]],\n",
    "                features[FEATURES[variant][2]],\n",
    "                features[FEATURES[variant][3]],\n",
    "            ]\n",
    "        )\n",
    "        y_val.append(class_idx)\n",
    "\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = (x_val - means) / stds\n",
    "\n",
    "y_val_predicted = np.zeros(val.shape[0])\n",
    "\n",
    "for i in range(val.shape[0]):\n",
    "    distances = np.linalg.norm(val[i] - train, axis=1)\n",
    "    k_nearest_idx = np.argsort(distances.ravel())[:k]\n",
    "    kinds, counts = np.unique(y_train[k_nearest_idx], return_counts=True)\n",
    "    top_count = np.argmax(counts)\n",
    "    y_val_predicted[i] = kinds[top_count]\n",
    "\n",
    "print(f\"Accuracy: {(y_val_predicted == y_val).mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Analyse der Ergebnisse ueber eine Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ggfs. ist sklearn in Eingabekonsole nach Aufruf von \"conda activate\" über \"pip install sklearn\" zu installieren\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "fig = plt.figure(figsize=(3, 3), layout=\"tight\")\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "conf_mat = confusion_matrix(y_val_predicted.astype(int), y_val.astype(int))\n",
    "ax.imshow(conf_mat, cmap=\"Blues\")\n",
    "indexes = np.arange(len(defect_classes))\n",
    "\n",
    "for i in indexes:\n",
    "    for j in indexes:\n",
    "        ax.text(j, i, conf_mat[i, j])\n",
    "ax.set_xticks(indexes, defect_classes, rotation=90)\n",
    "ax.set_xlabel(\"Wahrheit\")\n",
    "ax.set_yticks(indexes, defect_classes)\n",
    "ax.set_ylabel(\"Vorhersage\")\n",
    "ax.set_title(\"Confusion Matrix\")\n",
    "\n",
    "if EXPORT_REPORT:\n",
    "    ax.set_title(None)\n",
    "    fig.savefig(f\"report/images/confusion_matrix_var{variant}.eps\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Detailanalyse der fehlerhaften Klassifizierungen mit Anzeige der Bilder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_val)):\n",
    "    class_predicted = defect_classes[int(y_val_predicted[i])]\n",
    "    class_truth = defect_classes[int(y_val[i])]\n",
    "    comment = (\n",
    "        f\"Vorhersage: \\\\texttt{{{class_predicted}}}, \"\n",
    "        + f\"Wahrheit: \\\\texttt{{{class_truth}}} \"\n",
    "        + f\"({os.path.basename(filenames[i])})\"\n",
    "    )\n",
    "\n",
    "    if y_val_predicted[i] != y_val[i]:\n",
    "        img_bgr = cv2.imread(filenames[i])\n",
    "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "        img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "        img_segmented = variants[variant][\"apply_segmentation\"](img_gray)\n",
    "        img_segmented_rgb = cv2.cvtColor(img_segmented, cv2.COLOR_GRAY2RGB)\n",
    "        cnt, _ = variants[variant][\"exctact_features\"](img_segmented)\n",
    "        cv2.drawContours(img_rgb, cnt, -1, (255, 0, 0), 3)\n",
    "        cv2.drawContours(img_segmented_rgb, cnt, -1, (255, 0, 0), 3)\n",
    "        fig = plt.figure(figsize=(5.7, 2.25), layout=\"tight\")\n",
    "        ax = fig.add_subplot(1, 3, 1)\n",
    "        ax.imshow(img_gray, cmap=\"Greys_r\")\n",
    "        ax.set_title(\"Grauwerte\")\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        ax = fig.add_subplot(1, 3, 2)\n",
    "        ax.imshow(img_rgb)\n",
    "        ax.set_title(\"Grauw. mit Kontur\")\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        ax = fig.add_subplot(1, 3, 3)\n",
    "        ax.imshow(img_segmented_rgb)\n",
    "        ax.set_title(\"Segm. mit Kontur\")\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        fig.suptitle(comment)\n",
    "\n",
    "        if EXPORT_REPORT:\n",
    "            fig.savefig(\n",
    "                f\"report/images/error_analysis_var{variant}_\"\n",
    "                + f\"{os.path.splitext(os.path.basename(filenames[i]))[0]}.eps\",\n",
    "                pad_inches=0,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Hyperparameter Tuning\n",
    "\n",
    "Optimieren Sie Ihr Ergebnis und stellen Sie die Accuracy von mindestens 2 Varianten der Segmentierung und 2 Varianten von Merkmalskombinationen gegenüber $\\Rightarrow$ 4 Ergebnisse\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
